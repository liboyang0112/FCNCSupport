\section{FCNC signal samples}
\label{sec:fcncbkg}

The targeted signal in this analysis is $tqH/tH$ with $\Htautau$ (samples 411170-411177 and 412098-412105) in App. \ref{app:mc_sample_list}).
%In addition to the jet faking $\tauhad$ background, there is also background from fake leptons that do not come from prompt decays of $W$, $Z$ or tau lepton.
However, if the FCNC processes exists, the other decays of the Higgs can be part of the signal.
Therefore, samples xxxxxx-xxxxxx with inclusive $W$ and Higgs decays are also included. These sample have a one-lepton (electron or muon) filter at truth level (either coming from $W$ or Higgs decays). Events overlapping with xxxxxx-xxxxxx are removed based on truth information.

It is checked that after the final selection, there are 110 overlapped signal events caused by different overlap removal and object definition in xTauFramework and ttHMultiAna (27140 in total for hadhad channel and 95253 in total for lepton channels) but there is no overlap in the signal enriched region (BDT > 0.5).

The total FCNC signal with fake taus in this analysis is not used in the MVA training, but is regarded as part of the total signal in the fit. The normalization factor of the other components is common with the signal, so that their yields are fully correlated in the fit.

\section{Background estimation}
\label{sec:background}

The background events with real tau leptons are represented by Monte Carlo (MC) samples. These include $t\bar{t}$, $t\bar{t}+H/V$ and 
single top events with real taus, and $Z\to\tau\tau$+jets. The $Z\to ee,\mu\mu$ processes are included for lepton faking 
tau background, and the contribution from jet faking tau.
The fake background with one or more taus faked by jets consists of the top fake (with at least one fake tau from jets in the top events), 
QCD multijet, $W$+jets and diboson events. Where the top is dominant as shown in Figure \ref{fig:pt_raw}.

\input{\FCNCFigures/tex/pt_raw}

However, the charge of two taus candidates might be correlated in the $t\bar t$ events
when one of taus is a real tau from the $W\rightarrow \tau \nu$ decay while the other tau is a fake from a jet from other $W\rightarrow jj$ decay.
They are likely to carry the opposite charges to each other.  
Because of this charge asymmetry we have to calibrate the fake-tau modeling using a Data-Driven (DD) Scale Factor (SF) 
method by comparing the normalization of fake-tau events in MC to data in the control regions.
This SF is then applied to correct the normalization of tau fakes in the MC yields.
The excess of the events over these MC background is then from the multi-jets (QCD) faking background.

\subsection{Origin of fake $\tauhad$}
\label{sec:fake_origin}

Top fake is the largest fake background in the total fake in the leptonic channels. 
Within the top fake events, fake taus can come from different origins, i.e., from jets (heavy/light flavor quark or gluon initiated) 
or leptons (electron or muon). The tau fake 
origins are checked with the top MC. Three dedicated top pair production control regions are define for:
\begin{itemize}
\item{W-jet faking tau: exactly 1 lepton, exactly 1 tau candidate, at least 4 jets with exactly 2 b-tagged. Tau candidate and lepton have the same charge.}
\item{B-jet faking tau: 2 leptons with different flavors or away from Z pole ($M_{ll}>100\GeV$ or $M_{ll}<90\GeV$), exactly 1 tau candidate, exactly 1 b-tagged jet.}
\item{Radiation faking tau: 2 leptons with different flavors or away from Z pole, exactly 1 tau candidate, at least two jets with exactly 2 b-tagged jets.}
\end{itemize}
$\met > 20$GeV is required for the top control regions to ensure that QCD contribution is negligible. The detailed categorisation and plots are shown in section \ref{sec:sf_method}.
Most of the fake taus come from quark initiated jets, but the flavor distributions in OS are similar to those in SS. 
%However, these differences are well reproduced in the VR regions, which are also shown in Fig. \ref{fig:lh_fake_comp}. 
%Therefore, the VR events are important to cover systematics coming from fake tau origins as well. Similar fake origin 
%distributions in $\thadhad$ are shown in Fig. \ref{fig:hh_fake_comp}, although the top fake is only subdominant, and statistical errors are larger.

\subsection{MC fake $\tauhad$ estimation}
\label{sec:sf_method}

%Although the method mentioned in the \ref{sec:sf_method_obsolete} was adopted by the tthML analysis, a new method is needed in this case. 
As shown in the Figure \ref{fig:pt_raw}, the data is generally over-estimated in the OS regions while it is opposite in the SS region. If the fake taus are corrected by the same scale factors, this mismodelling will never get solved. This asymmetry of the SS and OS fake taus can be interpreted by the mis-modelling of the fake tau charges. Since the fake taus mainly come from light-flavored jets as shown in Figure \ref{fig:wjet_pt}, the mis-modelling is related to the charge carried by the jets. In conclusion, the mis-modelling is originated from the charge correlation between the jet which is faking a tau and the lepton. So the parent of the jet is believed to be charge correlated with the lepton. Considering the main background is $\bar{t}t$ process. The only suspect is the hadronic $W$ boson. In order to find the contribution of w-jet faking taus ($\tau_{W}$).  the truth information is used to match between the w-jet and the fake tau with $\Delta R < 0.4$. As shown in the Figure \ref{fig:wjet_pt}, there is a considerable amount of $\tau_{W}$'s in both SS and OS regions. There are four kinds of fake taus that need to be calibrated: Type1) $\tau_{W}$'s with the opposite charge of the lepton; Type2) $\tau_{W}$'s with the same charge of the lepton; Type 3) the fake taus from b-jets; Type4) the fake taus from other origins(mainly radiations). Many control regions are used to calibrate the four types.

%As presented in the Sec. \ref{sec:fake_origin}, the fake taus should be calibrated based on the three origins. The following top control regions are defined. A simulteneous fit is done in these region by floating the normalisation of the three kinds of fake taus. The fit result is shown in the Table \ref{tab:scale_factor}.

\begin{itemize}
\item{$2l1tau1bnj$: 2 leptons with different flavors or away from Z pole, exactly 1 tau candidate,  exactly 1 b-tagged jets.}
\item{$2l1tau2bnj$: 2 leptons with different flavors or away from Z pole, exactly 1 tau candidate,  exactly 2 b-tagged jets.}
\item{$1l1tau2b2j SS$: Exactly 1 lepton, exactly 1 tau candidate, exactly 4 jets with exactly 2 b-tagged. Tau candidate and lepton have the same charge.}
\item{$1l1tau2b2j OS$: Exactly 1 lepton, exactly 1 tau candidate, exactly 4 jets with exactly 2 b-tagged. Tau candidate and lepton have the opposite charge.}
\item{$1l1tau2b3j SS$: Exactly 1 lepton, exactly 1 tau candidate, at least 5 jets with exactly 2 b-tagged. Tau candidate and lepton have the same charge.}
\item{$1l1tau2b3j OS$: Exactly 1 lepton, exactly 1 tau candidate, at least 5 jets with exactly 2 b-tagged. Tau candidate and lepton have the opposite charge.}
\end{itemize}

Where di-lep regions ($2l1tau1b$ and $2l1tau2b$) are used to calibrate the Type3 and Type4 fake taus. As explained in the \ref{sec:fake_origin}, these regions are dominated by the bjet and the radiation jet faking taus. 2bOS regions ($1l1tau2b2j OS$ and $1l1tau2b3j OS$) are used to calibrate Type1 fake taus. Compared to the signal region, this region has an additional b-jet. So the $\bar{t}t$ background is enhanced in this region and signal is depleted. Similarly for the Type2 we can use 2bSS regions ($1l1tau2b2j SS$ and $1l1tau2b3j SS$) to calibrate. The components of these regions are shown in Figure \ref{fig:wjet_pt_CR}. Then a simultaneous fit is made to derive the scale factors for the fake taus. There are four parameters needed to be decided (the scale factors for the 4 types). But considering the $p_{T}$ and number of tracks depencence of the tau reconstruction, the scale factors are derived in 3 $\pt$ slices (25-35,35-45,45-inf)GeV and 1/3 prong taus. So there are 24 parameters to be decided. The results is shown in table \ref{tab:scale_factor_1prong_statonly} and \ref{tab:scale_factor_3prong_statonly}. All of the CP and theory uncerntainties are used to derive the uncertainty of the scale factors. The post-fit plots are shown in Figure \ref{fig:wjet_pt_postfit_CR}. Then the scale factors are applied to the corresponding single b-jet regions. In $l\thadhad$ channel, both taus can be fake, so the calibration is done to them separately, following the same procedure as $\tlhad$ channels using the lepton and fake tau charges, then the scale factors are multiplied together.

\begin{table}
\caption{The scale factors for 1 prong fake taus derived from the fit.}
\label{tab:scale_factor_1prong_statonly}
\input{\FCNCTables/fakeTauFit/scale_factor_1prong_statonly}
\end{table}
\begin{table}
\caption{The scale factors for 3 prong fake taus derived from the fit.}
\label{tab:scale_factor_3prong_statonly}
\input{\FCNCTables/fakeTauFit/scale_factor_3prong_statonly}
\end{table}
\input{\FCNCFigures/tex/wjet_pt}
\input{\FCNCFigures/tex/wjet_pt_CR}
\input{\FCNCFigures/tex/wjet_pt_postfit_CR}
\input{\FCNCFigures/tex/wjet_pt_postfit}

\subsection{QCD fake background in $\tlhad$ and $l\thad$ regions}

After the fake tau calibration, the fake lepton contribution from QCD is also estimated using ABCD method. For each $\tlhad$ and $l\thad$signal regions, 4 blocks are defined as follows:

\begin{itemize}
	\item A: $E_T^{miss}<20$GeV, PLV not tight
	\item B: $E_T^{miss}<20$GeV, PLV tight
	\item C: $E_T^{miss}>20$GeV, PLV not tight
	\item D: $E_T^{miss}>20$GeV, PLV tight
\end{itemize}
The transfer factors are measured in each signal region as $r=\frac{N_B}{N_A}$. Where $N_A$ and $N_B$ are the yields calculated by data-MC where MC includes real lepton background with real taus or calibrated fake taus. The results are shown in \ref{tab:FF}. The uncertainties in the table for each region contains statistical uncertainties during the calculation and the potential signal contribution ($BR=0.2\%$). In principle for the QCD estimation, the transfer factor should not depend on the number of jets and charge. At the same time, we see little pt dependence in the CRs. So all of the measurements are taken into consideration and the transfer factor central value and stat uncertainty are derived using likelihood method separately for election and muons. The systematics variation is taken by calculating the second moment among four regions. The combined result is shown as the last line in the table with both stats and systematics considered, where the stats. uncertainty for electron and muon are 0.13 and 0.07 respectively. So the systematic uncertainties are comparable with the stats uncertainties, which indicates that there is no big deviation among the 4 measurements.

\begin{table}
\caption{The QCD transfer factor derived from different low $E_T^{miss}$ control regions}
\label{tab:FF}
\input{\FCNCTables/FF/fakeFactor}
\end{table}

Then the QCD contribution in D is then estimated as $rC$. After the ABCD QCD estimation, the signal region is redefined as D.
The data-MC comparison after the fake tau and fake lepton estimation is show in Figure \ref{fig:wjet_pt_postfit}.


\subsection{fake $\tauhad$ estimate in $\thadhad$}
\label{sec:ss_method}

Figure \ref{fig:os_pre_hadhad} shows the $\tauhad$ $\pt$ spectra in the $\thadhad$ SS and OS. The fake tau background events from QCD multi-jets 
is not added yet so the data have more than the background prediction. The top fake are dominated by fakes with one real tau.
It is found, based on the MC prediction, that the QCD fake is the dominant fake process in the $\thadhad$ channel.Here,we employ a so-called Fake Factor Method developed by  $H\rightarrow$ $\thadhad$ coupling people.If one would like to  investigate the method details about the method,  you will find them in their document( add link). We will demostrate how the method are applied in our analysis.

First, we need to define some regions for estimating the fake:

\begin{itemize}
\item{$reg2matau1b2jos$:   2 opposite $\tauhad$  with RNN medium ID, one b-jet, 2 exactly light flavor jets.}
\item{$reg1m1ltau1b2jos$:  2 opposite $\tauhad$  with leading one being RNN medium,subleading being  RNN loose,one b-jet, 2 exactly light flavor jets.}
\item{$reg1l1mtau1b2jos$:  2 opposite $\tauhad$  with subleading one being RNN medium,leading being  RNN loose,one b-jet, 2 exactly light flavor jets.}
\item{$reg2ltau1b2jos$:    2 opposite $\tauhad$  with RNN loose but not RNN medium,one b-jet, 2 exactly light flavor jets.}
\item{$reg1l1ntau1b2jos$:  2 opposite $\tauhad$  with leading one being RNN loose-not-medium,subleading being not RNN medium,one b-jet, 2 exactly light flavor jets.}
\item{$reg1n1ltau1b2jos$:  2 opposite $\tauhad$  with subleading one being RNN loose-not-medium,leading being not RNN medium,one b-jet, 2 exactly light flavor jets.}
\end{itemize}

Here, we didn't ultilize the regions with two not loose $\tauhad$ (very loose $\tauhad$ ),since HIGG4D3 derivation removes all events with both $\tauhad$ failing the loose $\tauhad$ ID criteria. So we only concentrate on events with at least tau satisfying the loose RNN ID working point. In this control region, the template for the fake contribution is constructed by subtracting all simulated $\tauhad$ background contributions from the data distribution.

According to the strategy in the note, two sets of fake-factors are needed to be computed in the W+jets control region of $\tlhad$ channel to scale the template.It is necessary to have two sets because of the HIGG4D3 skimming. Therefore, fake-factors derived in a region with a loose minimum ID requirement must be applied in combination with those without it.In addition, we need to adjust some cut in wjet CR to make the fake-factors more applicable to $\tauhad$ channel.Here, we only list the cuts changed for fake-factor calculation:

\begin{itemize}
\item    Matching of the $\tauhad$ candidate to the tau25\_medium1\_tracktwo(EF) trigger

\item    Changing the b-tagging working point to 70\%

\item    Removing the lower RNN ID cut at 0.01

\item    Requiring $\Delta\eta (l,$\tauhad$)>0.6$
\end{itemize}

All cuts chosen here are just assure that the fake factor measurement is not biased. The two sets of Fake-factors are completed in three regions, differing in the tau ID working point requirment. We denote the FFs as not-medium FFs(nm) and loose-not-medium FFs(lnm), both of the FFs are the ratio of yields of events in W+jet CR with tau medium tau ID to yields of events fialing the tau ID, for lnm, we require the ID criteria down to loose but not medium tau.The nm are calculated with a denominator where the tau candidates fail the medium ID, More specifically, the FF are deacribes as this: 

\begin{equation}
F F_{\mathrm{nm}}=(\text { Data }-\mathrm{MC})_{\text {medium } \tau_{\text {had-vis }}}^{\mathrm{WCR}} /(\text { Data }-\mathrm{MC})_{\text {not-medium}\ \tau_{\text{had-vis}}}^{\mathrm{WCR}} 
\end{equation}

\begin{equation}
F F_{\mathrm{lnm}}=(\text { Data }-\mathrm{MC})_{\text {medium } \tau_{\text {had-vis }}}^{\mathrm{WCR}} /(\text { Data }-\mathrm{MC})_{\text {loose-not-medium}\ \tau_{\text{had-vis}}}^{\mathrm{WCR}}
\end{equation}

A 2-dimensional parametrization is employed in the light of the dependence on pt and $\eta$. From the FF definition, we can give a pictorial explanation of the computation of FF.From the idea in the $H\rightarrow$ $\thadhad$ coupling note,the ata-driven method to investigate the Signal Region yields from fakes are organized as follows.

The template for double-fake events is anti-tau region, which could be divided into three smaller regions according to the different taus candidate ID and HIGG4D3 derivation framework:leading tau with loose-not-medium ID and subleading tau with not loose ID which is marked in orange in the figure(add figure), leading tau with not loose ID and subleading tau with loose-not-medium which is marked in green, both of leading tau and subleading pass loose-not-medium working point which locate in the intersection of the previous two regions, which are corresponding to our $reg1l1ntau1b2jos$,$reg1n1ltau1b2jos$,$reg2ltau1b2jos$ respectively.

From the fake-factor definition, $F F_{\operatorname{lnm}}\left(\tau_{0}\right) \cdot F F_{\mathrm{nm}}\left(\tau_{1}\right)$ will scale the $reg1l1ntau1b2jos$ to full expected fake tields in the SR,  in the same way, $F F_{\mathrm{nm}}\left(\tau_{0}\right) \cdot F F_{\mathrm{lnm}}\left(\tau_{1}\right)$, This would result in an overestimation of the SR fake contribution by a factor of two, which is resolved by multiplying the applied product of two fake-factors by $\frac{1}{2}$.

Besides, Events with both $\thadhad$ candidates satisfying the loose criterion are scaled 
by $\frac{1}{2}\left(F F_{\operatorname{lnm}}\left(\tau_{0}\right) \cdot F F_{\mathrm{nm}}\left(\tau_{1}\right)+F F_{\mathrm{nm}}\left(\tau_{0}\right) \cdot F F_{\operatorname{lnm}}\left(\tau_{1}\right)\right)$ to account for these events being intersection of two template regions.

Finally, we also take events with only one fake $\thadhad$ into account to complete our Fake computation,for these, $reg1m1ltau1b2jos$ and $reg1l1mtau1b2jos$ are needed to be added, which are scaled by $F F_{\mathrm{nm}}\left(\tau_{1}\right)$ and $F F_{\mathrm{nm}}\left(\tau_{0}\right)$,respectively.

The procedure described in the previous paragraphs are summarized in the following equation,

\begin{equation}
\tau_{1}^{P} \tau_{2}^{P}=\tau_{1}^{T} \tau_{2}^{T}(\mathrm{MC})+F F_{2} \tau_{1}^{P} \tau_{2}^{F}+F F_{1} \tau_{1}^{F} \tau_{2}^{P}-F F_{1} F F_{2} \tau_{1}^{F} \tau_{2}^{F}
\end{equation}

where P means passing $\thadhad$ ID, T means truth $\thadhad$, therefore, the equation illustrates the contribution of events with two RNN medium $\thadhad$ is estimated through the combination of $reg1m1ltau1b2jos$, $reg1l1mtau1b2jos$, $reg2ltau1b2jos$,$reg1l1ntau1b2jos$,$reg1n1ltau1b2jos$.

Since the sample size limitations in the W+jets control region,statistical uncertainties on the regions where the FFs are derived
and applied need to been considered.We will vary the fake factors by one standard deviation of the statistical uncertainty originating from the limited sample size to implement the systematic variations.The fake-factors from the W+jets CR depending on $\thadhad$ prongness and the type (lnm or nm)are derived separately, so there are four systematic variations to cover for it.

We also derived the fake factors in the SS region using the same binning applied in the W+jets, which are called same-sign CR fake-factors.These fake factors are then applied to SS anti-ID to build the  the fake template for the closure test. In the final fit procedure, this variation is also taken into account.


\begin{figure}[htb]
\centering
\includegraphics[page=6,width=0.45\textwidth]{\FCNCFigures/xTFW/raw/NOMINAL/reg2mtau1b2jss/tau_pt_0.pdf}
\put(-100, 140){\textbf{(a)}}
\put(-120, 130){\footnotesize{STH $\thadhad$ (SS)}}
\includegraphics[page=6,width=0.45\textwidth]{\FCNCFigures/xTFW/raw/NOMINAL/reg2mtau1b2jos/tau_pt_0.pdf}
\put(-100, 140){\textbf{(b)}}
\put(-120, 130){\footnotesize{STH $\thadhad$ (OS)}}\\
\includegraphics[page=6,width=0.45\textwidth]{\FCNCFigures/xTFW/raw/NOMINAL/reg2mtau1b3jss/tau_pt_0.pdf}
\put(-100, 140){\textbf{(c)}}
\put(-120, 130){\footnotesize{TTH $\thadhad$ (SS)}}
\includegraphics[page=6,width=0.45\textwidth]{\FCNCFigures/xTFW/raw/NOMINAL/reg2mtau1b3jos/tau_pt_0.pdf}
\put(-100, 140){\textbf{(d)}}
\put(-120, 130){\footnotesize{TTH $\thadhad$ (OS)}}
\caption{ The distributions of $\tau$ $\pt$ in the STH $\thadhad$ (SS)(a), STH $\thadhad$ (OS) (b), TTH $\thadhad$ (SS) (c) 
and TTH $\thadhad$ (OS) (d), to illustrate the background composition. Data is more than the prediction because the fake tau backgrounds are missing. }
\label{fig:os_pre_hadhad}
\end{figure}

% The excess of the SS events over MC with truth taus are used to estimate the fake tau background in OS from QCD multi-jets in the $% \thadhad$ + jets channel:   
% \begin{equation}
% N_{\text{QCD fake}}^{\text{OS}} =f_{\text{norm}}\cdot (N_{\text{data}}^{\text{SS}} - N_{\text{MC}}^{\text{SS}}),
% \label{eq:eq10}
% \end{equation}
% 
% where $f_{\text{norm}}$ is a ratio of OS and SS from multi-jets QCD, 
% $N_{\text{data}}^{\text{SS}}$, and $N_{\text{MC}}^{\text{SS}}$ are observed data and estimated MC predictions in the SS regions. 
% 
% The $f_{\text{norm}}$ is measured separately to be $1.32\pm 0.03$ in the signal-depleted
% one $b$-tag events with $BDT<0.5$ and $1.6\pm 0.1$ in the double $b$-tagged  $\thadhad$ +$\ge$ 3jets events,
% which provides a good closure test of QCD fake tau estimation. We take the difference between these
% two values as a systematics for the method and assign $f_{\text{norm}}=1.3\pm 0.3$ for the analysis.



\subsection{Fake lepton background}
\label{sec:fcnc_fakeLep_bkg}

The fake lepton background in $\tlhad$ and lepton+$\thadhad$, which is estimated from MC\footnote{This includes fake lepton + real tau events
from all MC samples, namely, top, $W/Z$+jets, diboson}, is about $0.3$-$0.5\%$ of the total background. It constitutes
such a negligible fraction because a very high lepton $\pt$ threshold is already required at the trigger level. This
background is varied by $100\%$ as a conservative systematics.

\subsection{Summary of signal and background events}
\label{sec:background_hadhad}

We estimate the expected signal and background events in different regions, which are summarized in Table~\ref{tab:yield}. 


Figure~\ref{fig:pt_frs} shows the leading $\tauhad$ $\pt$ distribution from the OS events in the $\thadhad$ signal regions where the points are data
and the histograms as the expected various backgrounds.

\begin{figure}[htb]
\centering
\includegraphics[page=6,width=0.45\textwidth]{\FCNCFigures/xTFW/showFake/NOMINAL/reg2mtau1b2jos/tau_pt_0.pdf}
\put(-100, 140){\textbf{(a)}}
\put(-120, 130){\footnotesize{STH $\thadhad$ OS}}
\includegraphics[page=6,width=0.45\textwidth]{\FCNCFigures/xTFW/showFake/NOMINAL/reg2mtau1b3jos/tau_pt_0.pdf}
\put(-100, 140){\textbf{(b)}}
\put(-120, 130){\footnotesize{TTH $\thadhad$ OS}}\\
\caption{ The distributions of leading$\tau$ $\pt$ in the $\thadhad$ + 3 jets (a), and 4 jets OS (b)}
\label{fig:pt_frs}
\end{figure}
 
\clearpage
