\section{FCNC signal samples}
\label{sec:fcncbkg}

The targeted signal in this analysis is $tqH/tH$ with $\Htautau$ (samples 411170-411177 and 412098-412105) in App. \ref{sec:DSIDlist}).
%In addition to the jet faking $\tauhad$ background, there is also background from fake leptons that do not come from prompt decays of $W$, $Z$ or tau lepton.
Considering the other decays of the Higgs can be part of the signal, samples xxxxxx-xxxxxx (To be added with the samples used by tH bb group) with inclusive $W$ and Higgs decays are also included. These sample have a one-lepton (electron or muon) filter at truth level (either coming from $W$ or Higgs decays). Events overlapping with xxxxxx-xxxxxx are removed based on truth information.

It is checked that after the final selection, there are 110 overlapped signal events caused by different overlap removal and object definition in xTauFramework and ttHMultiAna (27140 in total for hadhad channel and 95253 in total for lepton channels) but there is no overlap in the signal enriched region (BDT > 0.5).

The total FCNC signal with fake taus in this analysis is not used in the MVA training, but is regarded as part of the total signal in the fit. The normalization factor of the other components is common with the signal, so that their yields are fully correlated in the fit.

\section{Background estimation}
\label{sec:background}

The background events with real tau leptons are represented by Monte Carlo (MC) samples. These include $t\bar{t}$, $t\bar{t}+H/V$ and 
single top events with real taus, and $Z\to\tau\tau$+jets. The $Z\to ee,\mu\mu$ processes are included for lepton faking 
tau background.
The fake background with one or more taus faked by jets consists of the top fake (with at least one fake tau from jets in the top events), 
QCD multijet, $W$+jets and diboson events. Where the $t\bar t$ is dominant as shown in Figure \ref{fig:pt_raw}.

\input{\FCNCFigures/tex/pt_raw}

\subsection{Fake tau estimation in leptonic channels}
\label{sec:sf_method}

Due to the large yield in the leptonic channels, tighter tau selection is applied, which limits the use of control regions with loosened tau identifications. the QCD background is much smaller than Monte Carlo events, so the MC events are used to model the fake taus. The fake taus are calibrated using Data-Driven (DD) Scale Factors (SF) derived by comparing the normalization of fake-tau events in MC to data in the control regions.
This SF is then applied to correct the normalization of tau fakes in the MC yields. The excess of the events over these MC background is then from the multi-jets (QCD) faking background.

Top fake is the largest fake background in the total fake in the leptonic channels, which contributes around 70\% to 99\% in different regions.
Within the top fake events, fake taus can come from different origins, i.e., from jets (heavy/light flavor quark or gluon initiated) 
or leptons (electron or muon). The tau fake 
origins are checked with the top MC. Three dedicated top pair production control regions are define for:
\begin{itemize}
\item{W-jet faking tau: exactly 1 lepton, exactly 1 tau candidate, at least 4 jets with exactly 2 b-tagged. Tau candidate and lepton have the same charge.}
\item{B-jet faking tau: 2 leptons with different flavors or away from Z pole ($M_{ll}>100\GeV$ or $M_{ll}<90\GeV$), exactly 1 tau candidate, exactly 1 b-tagged jet.}
\item{Radiation faking tau: 2 leptons with different flavors or away from Z pole, exactly 1 tau candidate, at least two jets with exactly 2 b-tagged jets.}
\end{itemize}
$\met > 20$GeV is required for the top control regions to ensure that QCD contribution is negligible. The detailed categorisation and plots are shown in section \ref{sec:sf_method}.
Most of the fake taus come from quark initiated jets, but the flavor distributions in OS are similar to those in SS. 

%However, these differences are well reproduced in the VR regions, which are also shown in Fig. \ref{fig:lh_fake_comp}. 
%Therefore, the VR events are important to cover systematics coming from fake tau origins as well. Similar fake origin 
%distributions in $\thadhad$ are shown in Fig. \ref{fig:hh_fake_comp}, although the top fake is only subdominant, and statistical errors are larger.

%Although the method mentioned in the \ref{sec:sf_method_obsolete} was adopted by the tthML analysis, a new method is needed in this case. 
As shown in the Figure \ref{fig:pt_raw}, the data is generally over-estimated in the OS regions while it is opposite in the SS region. If the fake taus are corrected by the same scale factors, this mismodelling will never get solved. This asymmetry of the SS and OS fake taus can be interpreted by the mis-modelling of the fake tau charges. Since the fake taus mainly come from light-flavored jets as shown in Figure \ref{fig:wjet_pt}, the mis-modelling is related to the charge carried by the jets. In conclusion, the mis-modelling is originated from the charge correlation between the jet which is faking a tau and the lepton. So the parent of the jet is believed to be charge correlated with the lepton. Considering the main background is $\bar{t}t$ process. The only suspect is the hadronic $W$ boson. In order to find the contribution of w-jet faking taus ($\tau_{W}$).  the truth information is used to match between the w-jet and the fake tau with $\Delta R < 0.4$. As shown in the Figure \ref{fig:wjet_pt}, there is a considerable amount of $\tau_{W}$'s in both SS and OS regions. There are four kinds of fake taus that need to be calibrated: Type1) $\tau_{W}$'s with the opposite charge of the lepton; Type2) $\tau_{W}$'s with the same charge of the lepton; Type 3) the fake taus from b-jets; Type4) the fake taus from other origins(mainly radiations). The following control regions are used to calibrate the four types.

%As presented in the Sec. \ref{sec:fake_origin}, the fake taus should be calibrated based on the three origins. The following top control regions are defined. A simulteneous fit is done in these region by floating the normalisation of the three kinds of fake taus. The fit result is shown in the Table \ref{tab:scale_factor}.

\begin{itemize}
\item{$2l1tau1bnj$: 2 leptons with different flavors or away from Z pole, exactly 1 tau candidate,  exactly 1 b-tagged jets.}
\item{$2l1tau2bnj$: 2 leptons with different flavors or away from Z pole, exactly 1 tau candidate,  exactly 2 b-tagged jets.}
\item{$1l1tau2b2j SS$: Exactly 1 lepton, exactly 1 tau candidate, exactly 4 jets with exactly 2 b-tagged. Tau candidate and lepton have the same charge.}
\item{$1l1tau2b2j OS$: Exactly 1 lepton, exactly 1 tau candidate, exactly 4 jets with exactly 2 b-tagged. Tau candidate and lepton have the opposite charge.}
\item{$1l1tau2b3j SS$: Exactly 1 lepton, exactly 1 tau candidate, at least 5 jets with exactly 2 b-tagged. Tau candidate and lepton have the same charge.}
\item{$1l1tau2b3j OS$: Exactly 1 lepton, exactly 1 tau candidate, at least 5 jets with exactly 2 b-tagged. Tau candidate and lepton have the opposite charge.}
\end{itemize}

Where di-lep regions ($2l1tau1b$ and $2l1tau2b$) are used to calibrate the Type3 and Type4 fake taus. These regions are dominated by the bjet and the radiation jet faking taus. $1l1tau2b2j OS$ and $1l1tau2b3j OS$ are used to calibrate Type1 fake taus. Compared to the signal region, this region has an additional b-jet. So the $\bar{t}t$ background is enhanced in this region and signal is depleted. Similarly for the Type2, regions $1l1tau2b2j SS$ and $1l1tau2b3j SS$ are chosen. The components of these regions are shown in Figure \ref{fig:wjet_pt_CR}. A simultaneous fit is made to derive the scale factors for the fake taus. There are four parameters needed to be decided (the scale factors for the 4 types). But considering the $p_{T}$ and number of tracks depencence of the tau reconstruction, the scale factors are derived in 3 $\pt$ slices (25-35,35-45,45-inf)GeV and 1/3 prong taus. So there are 24 parameters to be decided. The results are shown in table \ref{tab:scale_factor_1prong_statonly} and \ref{tab:scale_factor_3prong_statonly}. Where the errors are stats only. The post-fit plots are shown in Figure \ref{fig:wjet_pt_postfit_CR}. Then the scale factors are applied to the corresponding single b-jet regions. In $l\thadhad$ channel, both taus can be fake, so the calibration is done to them separately, following the same procedure as $\tlhad$ channels using the lepton and fake tau charges, then the scale factors are multiplied together. The nominal value of the scale factors will vary along with other CP and theory uncertainties in the final fit.

\begin{table}
\caption{The scale factors for 1 prong fake taus derived from the fit.}
\label{tab:scale_factor_1prong_statonly}
\input{\FCNCTables/fakeTauFit/scale_factor_1prong_statonly}
\end{table}
\begin{table}
\caption{The scale factors for 3 prong fake taus derived from the fit.}
\label{tab:scale_factor_3prong_statonly}
\input{\FCNCTables/fakeTauFit/scale_factor_3prong_statonly}
\end{table}
\input{\FCNCFigures/tex/wjet_pt}
\input{\FCNCFigures/tex/wjet_pt_CR}
\input{\FCNCFigures/tex/wjet_pt_postfit_CR}
\input{\FCNCFigures/tex/wjet_pt_postfit}

\subsection{QCD fake background in $\tlhad$ and $l\thad$ regions}

After the fake tau calibration, the fake contribution from QCD with both fake lepton and fake tau is also estimated using ABCD method. For each $\tlhad$ and $l\thad$ signal regions, 4 blocks are defined as follows:

\begin{itemize}
	\item A: $E_T^{miss}<20$GeV, PLV not tight
	\item B: $E_T^{miss}<20$GeV, PLV tight
	\item C: $E_T^{miss}>20$GeV, PLV not tight
	\item D: $E_T^{miss}>20$GeV, PLV tight
\end{itemize}
The transfer factors are measured in each signal region as $r=\frac{N_B}{N_A}$. Where $N_A$ and $N_B$ are the yields calculated by data-MC where MC includes real lepton background with real taus or calibrated fake taus. The results are shown in \ref{tab:FF}. The uncertainties in the table for each region contains statistical uncertainties during the calculation and the potential signal contribution ($BR=0.2\%$). In principle for the QCD estimation, the transfer factor should not depend on the number of jets and charge. So all of the measurements are taken into consideration to derive the transfer factor. The central value and stat uncertainty of the transfer factor are derived using likelihood method separately for election and muons. The systematics variation is taken by calculating the second moment among the four regions. The combined result is shown as the last line in the table with both stats and systematics considered, where the stats. uncertainty for electron and muon are 0.13 and 0.07 respectively. So the systematic uncertainties are comparable with the stats uncertainties, which indicates that there is no big deviation among the 4 measurements.

\begin{table}
\caption{The QCD transfer factor derived from different low $E_T^{miss}$ control regions}
\label{tab:FF}
\input{\FCNCTables/FF/fakeFactor}
\end{table}

Then the QCD contribution in D is then estimated as $rC$. After the ABCD QCD estimation, the signal region is redefined as D.
The data-MC comparison after the fake tau and fake lepton estimation is show in Figure \ref{fig:wjet_pt_postfit}.


\subsection{Fake tau estimate in hadronic channels}
\label{sec:ss_method}

In the hadronic channels, the QCD also contributes to the fake tau background. So the QCD and top fake background are estimated together using loose tau control regions.

The $\tauhad$ $\pt$ spectra in the $\thadhad$ SS and OS are shown in Figure \ref{fig:os_pre_hadhad}, where the data is far beyond the background prediction, which only contains real tau background. A Fake Factor Method developed by $H\rightarrow\thadhad$ group \cite{Htautau-note} is adopted and customized for this analysis. 

The following regions are defined to estimate the fake taus in STH $\thadhad$:

\begin{itemize}
\item{$2mtau1b2jos$: 2 opposite charged $\tauhad$ with medium RNN ID, one b-jet, exactly 2 light flavor jets.}
\item{$1m1ltau1b2jos$: 2 opposite charged $\tauhad$ with leading one RNN medium, subleading one RNN loose-not-medium, one b-jet, exactly 2 light flavor jets.}
\item{$1l1mtau1b2jos$: 2 opposite charged $\tauhad$ with subleading one RNN medium,leading one RNN loose-not-medium, one b-jet, exactly 2 light flavor jets.}
\item{$2ltau1b2jos$: 2 opposite charged RNN loose-not-medium $\tauhad$, one b-jet, exactly 2 light flavor jets.}
\item{$1l1ntau1b2jos$: 2 opposite charged $\tauhad$ with leading one RNN loose-not-medium, subleading one not loose (very loose), one b-jet, exactly 2 light flavor jets.}
\item{$1n1ltau1b2jos$: 2 opposite charged $\tauhad$ with subleading one RNN loose-not-medium, leading one not loose (very loose), one b-jet, exactly 2 light flavor jets.}
\end{itemize}

For TTH $\thadhad$ region, the definition is the same except that the number of light jets requirement is at least 3. Figure \ref{fig:regions_hadhad} shows the pictorial representation of all regions required by FF. In these control regions, the template for the fake tau contribution aquired by subtracting all real $\tauhad$ background contributions from data.

\begin{figure}[htb]
\centering
\includegraphics[width=0.45\textwidth]{\FCNCFigures/xTFW/otherPlots/regions.png}
\caption{Pictorial representation of the fake-factors relevant region for $\tauhad$ channel.}
\label{fig:regions_hadhad}
\end{figure}


Two sets of fake-factors need to be computed in the W+jets control region of $\tlhad$ channel to scale the template. It is necessary to have two sets because of the HIGG4D3 skimming. Therefore, fake-factors derived in a region with a loose minimum ID requirement must be applied in combination with those without. In addition, we need to adjust some cut in wjet CR to make the fake-factors more applicable to $\tauhad$ channel.Here, we only list the cuts changed for fake-factor calculation:

\begin{itemize}
\item    Matching of the $\tauhad$ candidate to the tau25\_medium1\_tracktwo(EF) trigger

\item    Changing the b-tagging working point to 70\%

\item    Removing the lower RNN ID cut at 0.01

\item    Requiring $\Delta\eta (l,$\tauhad$)>0.6$
\end{itemize}

All cuts chosen here are just assure that the fake factor measurement is not biased. The two sets of Fake-factors are completed in three regions, differing in the tau ID working point requirment. We denote the FFs as not-medium FFs(nm) and loose-not-medium FFs(lnm), both of the FFs are the ratio of yields of events in W+jet CR with tau medium tau ID to yields of events fialing the tau ID, for lnm, we require the ID criteria down to loose but not medium tau.The nm are calculated with a denominator where the tau candidates fail the medium ID, More specifically, the FF are deacribes as this: 

\begin{equation}
F F_{\mathrm{nm}}=(\text { Data }-\mathrm{MC})_{\text {medium } \tau_{\text {had-vis }}}^{\mathrm{WCR}} /(\text { Data }-\mathrm{MC})_{\text {not-medium}\ \tau_{\text{had-vis}}}^{\mathrm{WCR}} 
\end{equation}

\begin{equation}
F F_{\mathrm{lnm}}=(\text { Data }-\mathrm{MC})_{\text {medium } \tau_{\text {had-vis }}}^{\mathrm{WCR}} /(\text { Data }-\mathrm{MC})_{\text {loose-not-medium}\ \tau_{\text{had-vis}}}^{\mathrm{WCR}}
\end{equation}

A 2-dimensional parametrization is employed in the light of the dependence on pt and $\eta$. From the FF definition, we can give a pictorial explanation of the computation of FF.From the idea in the $H\rightarrow$ $\thadhad$ coupling note,the ata-driven method to investigate the Signal Region yields from fakes are organized as follows.

The template for double-fake events is anti-tau region, which could be divided into three smaller regions according to the different taus candidate ID and HIGG4D3 derivation framework:leading tau with loose-not-medium ID and subleading tau with not loose ID which is marked in orange in the figure(add figure), leading tau with not loose ID and subleading tau with loose-not-medium which is marked in green, both of leading tau and subleading pass loose-not-medium working point which locate in the intersection of the previous two regions, which are corresponding to our $1l1ntau1b2jos$,$1n1ltau1b2jos$,$2ltau1b2jos$ respectively.

From the fake-factor definition, $F F_{\operatorname{lnm}}\left(\tau_{0}\right) \cdot F F_{\mathrm{nm}}\left(\tau_{1}\right)$ will scale the $1l1ntau1b2jos$ to full expected fake tields in the SR,  in the same way, $F F_{\mathrm{nm}}\left(\tau_{0}\right) \cdot F F_{\mathrm{lnm}}\left(\tau_{1}\right)$, This would result in an overestimation of the SR fake contribution by a factor of two, which is resolved by multiplying the applied product of two fake-factors by $\frac{1}{2}$.

Besides, Events with both $\thadhad$ candidates satisfying the loose criterion are scaled 
by 

$\frac{1}{2}\left(F F_{\operatorname{lnm}}\left(\tau_{0}\right) \cdot F F_{\mathrm{nm}}\left(\tau_{1}\right)+F F_{\mathrm{nm}}\left(\tau_{0}\right) \cdot F F_{\operatorname{lnm}}\left(\tau_{1}\right)\right)$ to account for these events being intersection of two template regions.

Finally, we also take events with only one fake $\thadhad$ into account to complete our Fake computation,for these, $1m1ltau1b2jos$ and $1l1mtau1b2jos$ are needed to be added, which are scaled by $F F_{\mathrm{nm}}\left(\tau_{1}\right)$ and $F F_{\mathrm{nm}}\left(\tau_{0}\right)$,respectively.

The procedure described in the previous paragraphs are summarized in the following equation,

\begin{equation}
\tau_{1}^{P} \tau_{2}^{P}=\tau_{1}^{T} \tau_{2}^{T}(\mathrm{MC})+F F_{2} \tau_{1}^{P} \tau_{2}^{F}+F F_{1} \tau_{1}^{F} \tau_{2}^{P}-F F_{1} F F_{2} \tau_{1}^{F} \tau_{2}^{F}
\end{equation}

where P means passing $\thadhad$ ID, T means truth $\thadhad$, therefore, the equation illustrates the contribution of events with two RNN medium $\thadhad$ is estimated through the combination of $1m1ltau1b2jos$, $1l1mtau1b2jos$, $2ltau1b2jos$,$1l1ntau1b2jos$,$1n1ltau1b2jos$.

Since the sample size limitations in the W+jets control region,statistical uncertainties on the regions where the FFs are derived
and applied need to been considered.We will vary the fake factors by one standard deviation of the statistical uncertainty originating from the limited sample size to implement the systematic variations.The fake-factors from the W+jets CR depending on $\thadhad$ prongness and the type (lnm or nm)are derived separately, so there are four systematic variations to cover for it.

We also derived the fake factors in the SS region using the same binning applied in the W+jets, which are called same-sign CR fake-factors.These fake factors are then applied to SS anti-ID to build the  the fake template for the closure test. In the final fit procedure, this variation is also taken into account.


\begin{figure}[htb]
\centering
\includegraphics[page=6,width=0.45\textwidth]{\FCNCFigures/xTFW/raw/NOMINAL/reg2mtau1b2jss/tau_pt_0.pdf}
\put(-100, 140){\textbf{(a)}}
\put(-120, 130){\footnotesize{STH $\thadhad$ (SS)}}
\includegraphics[page=6,width=0.45\textwidth]{\FCNCFigures/xTFW/raw/NOMINAL/reg2mtau1b2jos/tau_pt_0.pdf}
\put(-100, 140){\textbf{(b)}}
\put(-120, 130){\footnotesize{STH $\thadhad$ (OS)}}\\
\includegraphics[page=6,width=0.45\textwidth]{\FCNCFigures/xTFW/raw/NOMINAL/reg2mtau1b3jss/tau_pt_0.pdf}
\put(-100, 140){\textbf{(c)}}
\put(-120, 130){\footnotesize{TTH $\thadhad$ (SS)}}
\includegraphics[page=6,width=0.45\textwidth]{\FCNCFigures/xTFW/raw/NOMINAL/reg2mtau1b3jos/tau_pt_0.pdf}
\put(-100, 140){\textbf{(d)}}
\put(-120, 130){\footnotesize{TTH $\thadhad$ (OS)}}
\caption{ The distributions of $\tau$ $\pt$ in the STH $\thadhad$ (SS)(a), STH $\thadhad$ (OS) (b), TTH $\thadhad$ (SS) (c) 
and TTH $\thadhad$ (OS) (d), to illustrate the background composition. Data is more than the prediction because the fake tau backgrounds are missing. }
\label{fig:os_pre_hadhad}
\end{figure}

% The excess of the SS events over MC with truth taus are used to estimate the fake tau background in OS from QCD multi-jets in the $% \thadhad$ + jets channel:   
% \begin{equation}
% N_{\text{QCD fake}}^{\text{OS}} =f_{\text{norm}}\cdot (N_{\text{data}}^{\text{SS}} - N_{\text{MC}}^{\text{SS}}),
% \label{eq:eq10}
% \end{equation}
% 
% where $f_{\text{norm}}$ is a ratio of OS and SS from multi-jets QCD, 
% $N_{\text{data}}^{\text{SS}}$, and $N_{\text{MC}}^{\text{SS}}$ are observed data and estimated MC predictions in the SS regions. 
% 
% The $f_{\text{norm}}$ is measured separately to be $1.32\pm 0.03$ in the signal-depleted
% one $b$-tag events with $BDT<0.5$ and $1.6\pm 0.1$ in the double $b$-tagged  $\thadhad$ +$\ge$ 3jets events,
% which provides a good closure test of QCD fake tau estimation. We take the difference between these
% two values as a systematics for the method and assign $f_{\text{norm}}=1.3\pm 0.3$ for the analysis.

\subsection{Summary of signal and background events}
\label{sec:background_hadhad}

We estimate the expected signal and background events in different regions, which are summarized in Table~\ref{tab:yield}. 


Figure~\ref{fig:pt_frs} shows the leading $\tauhad$ $\pt$ distribution from the OS events in the $\thadhad$ signal regions where the points are data
and the histograms as the expected various backgrounds.

\begin{figure}[htb]
\centering
\includegraphics[page=6,width=0.45\textwidth]{\FCNCFigures/xTFW/showFake/NOMINAL/reg2mtau1b2jos_vetobtagwp70_highmet/tau_pt_0.pdf}
\put(-100, 140){\textbf{(a)}}
\put(-120, 130){\footnotesize{STH $\thadhad$ OS}}
\includegraphics[page=6,width=0.45\textwidth]{\FCNCFigures/xTFW/showFake/NOMINAL/reg2mtau1b3jos_vetobtagwp70_highmet/tau_pt_0.pdf}
\put(-100, 140){\textbf{(b)}}
\put(-120, 130){\footnotesize{TTH $\thadhad$ OS}}\\
\caption{ The distributions of leading$\tau$ $\pt$ in the $\thadhad$ + 3 jets (a), and 4 jets OS (b)}
\label{fig:pt_frs}
\end{figure}
 
\clearpage
