\section{Introduction}
\label{sec:intro}
Since the discovery of the Higgs boson in 2012, great efforts are made to study its properties. As the mass of the Higgs boson is about 125 GeV \cite{HiggsMass}, it is kinematically allowed that a top quark decays to a Higgs boson and an up-type quark via the flavour-changing neutral current (FCNC). In the Standard Model (SM), the FCNC interaction is forbidden at tree level and suppressed at higher orders due to the Glashow-Iliopoulos-Maiani (GIM) mechanism \cite{GIM}. The $t\to u/c+H$ branching fraction in the SM is calculated to be around $10^{-15}$ \cite{brtch3}. It would be enhanced in many models beyond the SM (BSM). Examples are the quark-singlet model \cite{quarkSinglet1,quarkSinglet2}, the two-Higgs doublet model with or without the flavour violation \cite{2hdm1,2hdm2}, the minimal supersymmetric standard model (MSSM) \cite{2hdm3}, supersymmetry with R-parity violation \cite{Rparity},
the Topcolour-assisted Technicolour model \cite{Techni} or models with warped extra dimensions \cite{extraD}, the little Higgs model with T-parity conservation \cite{littleH} and the composite Higgs models \cite{compositeH}.
Especially, the ansatz of Cheng and Sher \cite{Sher} allows a branching fraction of about $10^{-3}$ \cite{FCNC_rate}. Therefore, an observation of this decay would be a clear evidence for new physics. The $tqH$ interaction could also potentially open up more Higgs decay channels,
such as $H\rightarrow t^*q\rightarrow Wbq$, but they are likely suppressed due to the $t-H$ mass difference, which could be interesting for future studies.

On the other hand, if the $tqH$ interaction exists, the single-top, Higgs associated production through this interaction should also be enhanced. The $tH$ associated production in the SM prediction is expected to be small at LHC\cite{tHjb_production}. So the study on this process will also contribute to the FCNC interaction searches.

Upper $95\%$ CL limits on BR($t\to Hq$) have been obtained by ATLAS based on the data from 2015 and 2016, in the $H\to\gamma\gamma$ \cite{fcncgmgm}, $H\to WW/\tll$ multilepton \cite{fcncml} and  $\Htautau$, $H\to b\bar{b}$ \cite{fcnctautau} channels. The combined expected (observed) limits are $0.083\%$ ($0.11\%$) and $0.083\%$ ($0.12\%$) for $t\to Hc$ and $t\to Hu$ decay branching ratio, respectively. 

The $t\to Hq$ decay and $gq\to tH$ production are also searched by CMS based on the data from 2015 and 2016\cite{CMS-TOP-17-003} using the $H\to b\bar{b}$ decay. The branching ratio derived for $t\to Hc$ and $t\to Hu$ decay are $0.47\%$ ($0.44\%$) and $0.47\%$ ($0.34\%$) as expected (observed) limits respectively. CMS recently updated their search for $tqH$ in the $H\to b\bar{b}$ channel using
their full Run-2 data and  set observed(expected) upper limits on $\text{BR}(t\to Hu)$ of $7.9\times10^{-4}(1.1\times10^{-3})$ and $\text{BR}(t\to Hc)$ of $9.4\times10^{-4}(8.6\times10^{-4})$~\cite{CMS-PAS-TOP-19-002}.
CMS also recently reported a search for $tqH$ in the $H\rightarrow \gamma\gamma$ mode using the full Run-2 data and set observed(expected) upper limits on $\text{BR}(t\to Hu)$ of $1.9\times10^{-4}(3.1\times10^{-4})$ and $\text{BR}(t\to Hc)$ of $7.3\times10^{-4}(5.1\times10^{-4})$~\cite{CMS-PAS-TOP-20-007}.

The FCNC coupling is parametrised using dim-6 operators \cite{fcnc_production_theory}. The effective Lagrangian regarding $tqH$ interaction is:
%
\begin{equation}
\mathcal{L}_{EFT} = \frac{C^{i3}_{u\phi}}{\Lambda^{2}}(\phi^{\dagger}\phi)(\bar{q_{i}}t)\tilde{\phi} + \frac{C^{3i}_{u\phi}}{\Lambda^{2}}(\phi^{\dagger}\phi)(\bar{t_{i}}q)\tilde{\phi}
\label{eq:eq01}
\end{equation}
%
Where the operator notation is consistent with \cite{fcnc_production_theory} and the subscript i= 1,2 represents the generation of the light quark fields. 
The coefficient $C_{u\phi}$'s can be extracted as follows according to the Madgraph calculation using TopFCNC UFO:
\begin{equation}
\begin{array}{l}
(C^{i3}_{u\phi})^2 + (C^{3i}_{u\phi})^2 = 1946.6~\text{BR}(t\to qH)\\
(C^{13}_{u\phi})^2 + (C^{31}_{u\phi})^2 = \sigma(ug\to tH)/365.2~\text{fb}\\
(C^{23}_{u\phi})^2 + (C^{32}_{u\phi})^2 = \sigma(cg\to tH)/52.9~\text{fb}
\end{array}
\label{eq:eq02}
\end{equation}

To give a better impression on the numbers, we use $\text{BR}(t\to qH)=0.1\%$ as benchmark, which is corresponding to ($C^{13}_{u\phi})^2 + (C^{31}_{u\phi})^2=1.95$, $\sigma(ug\to tH)=710.9$ fb, $\sigma(cg\to tH)=103.0$ fb. The same TopFCNC UFO model has also been adapted by other FCNC $tqH$ searches in different Higgs decay $H\rightarrow\gamma\gamma$ and $H\rightarrow b\bar b$
channels~\cite{tqHgammagamma,tqHbb}. So ATLAS can combine these results together to get a better constrain on the FCNC coupling.  

In this article, a search is presented for the decay $t\to qH$ from one of top quarks in the $t\bar{t}$ production (\textit{TT}) and single-top, Higgs associated production (\textit{ST}) with $H\to\tau\tau$ where the remaining top decays into a $W$ boson and a $b$ quark as shown in Fig \ref{fig:diagrams} using 139~fb$^{-1}$ of proton-proton collision data at 13~TeV, taken with the ATLAS detector at the Large Hadron Collider (LHC). The final state is characterized by one top and one Higgs. In \textit{TT}, there is an additional $u$ or $c$ as $q$ quark forming a top resonance with Higgs.

\input{../FCNCFigures/tex/diagrams}

From the truth study as shown in the Figure \ref{fig:LHRHTruth}, the samples generated with left handed (LH) operator and right handed operator (RH) shows no difference. So the two sets of samples are merged together, weighted a factor of 0.5, for higher statistics.

\input{\FCNCFigures/tex/LHRHTruth}

\section{Analysis outline}

For the FCNC coupling search, we separate events in various signal regions (SR) defined in Sec. \ref{sec:SRs}, each focuses on
different $t\to Wb$ and $H\to\tau\tau$ decay final states in order to suppress the background.
The analysis also uses various $t\bar{t}$ control regions (CRtt) for calibration of tau fakes in Monte Carlo as well as
data-driven fake estimations from QCD multi-jet background, and finally BDT is trained to separate the
siganl and background processes in each SR. The output of
the SR BDT is used in a profile-likelihood fit in order to extract limits on the FCNC signal processes including all systematic uncertainties.

\subsection{Signal regions}
\label{sec:SRs}
As shown in the Figure \ref{fig:diagrams} in the final states containing $tt(qH)$ and $tH$, depending on the production modes and
the decay of $W$ boson hadronically and leptonically from the $t\to Wb$ decay referred as $t_h$ and $t_l$,
the signal is split into 4 kinds of final states as shown in Table \ref{tab:signalevents}. The contribution of $W\rightarrow\tau\nu$ is included either in 
$t_l$ when the $\tau$ decays into a light lepton(electron or muon) as $\tau_{lep}$ or in $t_h$ when the $\tau$ decays hadronically as $\thad$. 
 The $\Htautau$ decay are required to be in either $\tlhad$ or $\thadhad$ final states when the top decays hadronically ($t_h$) and only in $\thadhad$ when the top decay leptonically ($t_l$). The decay of $H\to\tll$ is dropped because this final state will be considered in the multi-lepton analysis. The decay of $H\to\tlhad$ is also dropped when top decay leptonically because in this case, the lepton fake could be important when both leptons have same-sign charge
and the overlap of the fake lepton and fake taus can be difficult to estimate.

Due to the low statistics in $t_lH$ and $t_lt(qH)$ processes, they are merged into a single region $t_l\thadhad$ where there is no light jet multiplicity requirement and the two $\tauhad$ are required to have opposite-sign charge. However there is a sizeable fraction of these events in which one of the taus fails the reconstruction and remains as a jet or goes missing due to
the low tau reconstruction efficiency. So the $t_l\thad$-1j and $t_l\thad$-2j are also included as signal regions where the lepton from $t_l$ and $\thad$ are required to have same-sign
charge in order to reduce $t\bar t$ background. For the $t_hH$ and $t_ht(qH)$ channels, the two tau candidates from the $\Htautau$ decay (including both $\tlhad$ and $\thadhad$) are required to have opposite-sign charge.  

The summary for the signal regions are listed in Table \ref{tab:signalregions} and their corresponding signal and background yields after fake estimation are shown
in Table \ref{tab:yield_SR} of which will be discussed in Sec.~\ref{sec:background}. 

For the future convenience, $t_h\tlhad$-2j and $t_h\tlhad$-3j are indicated by $t_h\tlhad$; $t_h\thadhad$-2j and $t_h\thadhad$-3j are indicated by $t_h\thadhad$; $t_l\tauhad$-2j and $t_l\tauhad$-1j are indicated by $t_l\tauhad$. All the of regions involving leptons from $t_l$ or $\taulep$ are indicated by "leptonic channels", otherwise hadronic channels".

\begin{table}
\footnotesize
\centering
\caption{Overview of the final states of signal events.}
\label{tab:signalevents}
\begin{tabular}[h]{c|c|c|c|c|c|c}
\hline \hline

\multicolumn{2}{c|}{\# of particles}	& alias & b-jet & jets & lepton(e /$\mu$) & taus\\ \hline
\multirow{2}{*}{\textit{ST}}	& $W\to l\nu$		& $t_lH$   & 1	    & 1    & 1      & 2   \\ \cline{2-7}
					& $W\to jj'$	& $t_hH$   & 1	    & 3    & 0      & 2   \\ \hline
\multirow{2}{*}{\textit{TT}}	& $W\to l\nu$		& $t_lt(qH)$   & 1	    & 2    & 1      & 2   \\ \cline{2-7}
					& $W\to jj'$	& $t_ht(qH)$   & 1	    & 4    & 0      & 2   \\ \hline
\end{tabular}
\footnotesize
\centering
\caption{Overview of the signal regions.}
\label{tab:signalregions}
\begin{tabular}[h]{c|c|c|c|c|c}
\hline \hline
Signal regions & b-jet & light flavor jets	& lepton(e /$\mu$) & hadronic taus & charge\\ \hline
$t_l\tauhad$-2j  & 1     & 2					& 1      & 1			 & $t_l\tauhad$ SS\\ \hline
$t_l\tauhad$-1j  & 1     & 1					& 1      & 1			 & $t_l\tauhad$ SS\\ \hline
$t_l\thadhad$	   & 1     & any				& 1      & 2             & $\thadhad$ OS\\ \hline
$t_h\thadhad$-2j & 1     & 2      			& 0      & 2             & $\thadhad$ OS\\ \hline
$t_h\thadhad$-3j & 1     & $\ge3$ 			& 0      & 2             & $\thadhad$ OS\\ \hline
$t_h\tlhad$-2j   & 1     & 2      			& 1      & 1             & $\tlhad$ OS\\ \hline
$t_h\tlhad$-3j   & 1     & $\ge3$ 			& 1      & 1             & $\tlhad$ OS\\ \hline
\end{tabular}
\end{table}

\begin{table}
\caption{The summary for the yield in the signal regions(the signal strength$\mu=1\to$ corresponds to BR$(t\to Hq)=0.1\%$).The quoted uncertainties are statistical uncertainties on the yields.In leptonic channel,the label Other MC means SM~Higgs,diboson,W+jets and $Z\to\tau\tau$  Monte Carlo with real $\tau$. Other fake $\tau$ represents contribution from light jet fakes. In hadronic channel, Fake means QCD jet or $t\bar{t}$ jet fake $\tau$. $only~\tau_{sub}~real$ means $t\bar{t}$ samples with sub leading $\tau$ being real. Rare includes single top samples and three tops samples contributions.}
\label{tab:yield_SR}
%\small
\footnotesize
\input{\FCNCTables/tthML/showFake/faketau/postfit/NOMINAL_SROnly/yield_chart}
\input{\FCNCTables/xTFW/showFake/NOMINAL/yield_chart}
\end{table}

\subsection{Analysis strategy for leptonic channels}

The main background contributing to the leptonic channels, defined in the last section, is top pair production as shown in Figure \ref{fig:intro_pt_raw}. It can either contribute as reducible or irreducible background. It's worth noting that
the bin contents in all the plots throughout the note are absolute, not divided by the bin size. 

\input{\FCNCFigures/tex/intro_pt_raw}

As irreducible background, when both tops decay leptonically to a $l$ and a $\tau$, and one of the $b$-jets from top decay fails the b-tagging, the event ends up in the $t_h\tlhad$ regions. This irreducible background is modelled directly by Monte Carlo.

For reducible background, when the top pair decays dileptonically, to a $l$ and a $\tauhad$, and one of the $b$-jets from top decay fails the b-tagging, if the $b$-jet or one of other jets is reconstructed as a $\tauhad$, the event could end up in the $t_l\thadhad$ regions if two $\tauhad$ have opposite-sign charge. When the top pair decays semi-leptonically, and one of jets fakes a $\tauhad$, the event could end up in the  $t_h\tlhad$ regions if the fake tau has the opposite charge to the lepton or in the $t_l\tauhad$ regions if the fake tau has the same charge as the lepton. 

The reducible background except QCD multi-jets fakes is modelled by Monte Carlo but with scale factors derived from the dedicated $t\bar{t}$ control regions (CRtt) using the SM
$t\bar{t}$ decay of dilepton events and semileptonically double-btagged lepton-jets events listed
in Table \ref{tab:sfcr} and explained in Sec. \ref{sec:sf_method}.

\begin{table}
\centering
\caption{Overview of the control regions used for fake tau scale factor derivation in leptonic channels compared to signal regions.}
\label{tab:sfcr}
\begin{tabular}[h]{c|c|c|c|c|c|c}
\hline \hline
\multicolumn{2}{c|}{Regions} & b-jet & light flavor jets	& lepton & hadronic taus & charge\\ \hline
\multirow{6}{*}{CRtt}&$t_lt_l1b\tauhad$	& 1     & any				& 2      & 1			 & $t_lt_l$ OS\\ \cline{2-7}
&$t_lt_l2b\tauhad$	& 2     & any				& 2      & 1			 & $t_lt_l$ OS\\ \cline{2-7}
&$t_lt_h2b\tauhad$-2jSS	& 2     & 2 				& 1      & 1             & $t_l\tauhad$ SS\\ \cline{2-7}
&$t_lt_h2b\tauhad$-2jOS	& 2     & 2      			& 1      & 1             & $t_l\tauhad$ OS\\ \cline{2-7}
&$t_lt_h2b\tauhad$-3jSS	& 2     & $\ge3$ 			& 1      & 1             & $t_l\tauhad$ SS\\ \cline{2-7}
&$t_lt_h2b\tauhad$-3jOS	& 2     & $\ge3$      		& 1      & 1             & $t_l\tauhad$ OS\\ \hline
\multirow{5}{*}{SR}&$t_l\tauhad$-2j  & 1     & 2					& 1      & 1			 & $t_l\tauhad$ SS\\ \cline{2-7}
&$t_l\tauhad$-1j  & 1     & 1					& 1      & 1			 & $t_l\tauhad$ SS\\ \cline{2-7}
&$t_l\thadhad$	   & 1     & any				& 1      & 2             & $\thadhad$ OS\\ \cline{2-7}
&$t_h\tlhad$-2j   & 1     & 2      			& 1      & 1             & $\tlhad$ OS\\ \cline{2-7}
&$t_h\tlhad$-3j   & 1     & $\ge3$ 			& 1      & 1             & $\tlhad$ OS\\ \hline
\end{tabular}
\end{table}

The QCD multi-jets also contribute a small fraction of the reducible background by faking both lepton and taus, especially in the low jet multiplicity region $t_l\tauhad$-1j. This is modelled by the ABCD method by cutting on $\met$ and the lepton isolation variable PLIV defined in Sec.~\ref{sec:Pliv} as explained in Sec.~\ref{sec:ABCD}.

\subsection{Analysis strategy for the Hadronic channels}

Similar to the leptonic channels, the $t\bar{t}$ also contributes to the hadronic channels as reducible and irreducible background. But in the hadronic channels, much larger contribution is observed both from $Z\to \tau\tau$ plus $b$-jet and from QCD multi-jets  with double fake taus as the excess of data events shown in Figure \ref{fig:intro_os_pre_hadhad}. 

\input{\FCNCFigures/tex/intro_os_pre_hadhad}

The irreducible background is modelled directly by Monte Carlo. The reducible background with sub-leading tau fake is modelled by Fake Factor (FF) method using the
fake-tau enriched control regions. The FFs are calculated from three different control regions listed below where one of taus failed the medium RNN tau cut, but passed
a minimum RNN$>0.01$ cut:

\begin{itemize}
	\item W+jet control region in the SM $\Htautau$ (Calculated by the $\Htautau$ group).
	\item SS control region, the two taus have the same charge and the rest selections are the same as signal region.
	\item OS control region, the events in the signal region that failing the kinematics cut defined in the Sec.~\ref{sec:cuts}.
\end{itemize}

The FF is applied to the fake tau control region where the subleading tau fails the medium requirement, to model the event with sub-leading taus faked in the signal region. The events with leading fake-tau are modelled by Monte Carlo with a conservative uncertainty of 50\% according to Sec.~\ref{sec:sf_method}.

\subsection{Statistical strategy}
\label{sec:statStrategy}

After fake estimation, BDT discriminants are trained in order to separate signal and backgrounds in each signal region.

A profile likelihood fit of the BDT discriminant in the SRs with NPs relating to the systematic uncertainties is made in order to set limits on the signal strengths.

\subsection{Blinding strategy}
\label{sec:blind}

In order to keep the analysis unbiased from artificial cut tunings some data histogram bins are blinded. Following the advice in the top group, the blinding threshold is quantified as S/B reaching 0.1 when assuming $B(t\rightarrow Hq)$ is 0.1\% which is the limit set by the 36fb$^{-1}$ combined results.

\section{Detector, data set and Monte Carlo simulation}

\subsection{ATLAS detector}
\label{sec:detector}

The ATLAS detector \cite{PERF-2007-01} at the LHC covers nearly the entire solid angle around the collision point. It consists of an inner tracking detector surrounded by a thin superconducting solenoid, electromagnetic and hadronic calorimeters, and a muon spectrometer incorporating three large superconducting toroid magnets.

The inner-detector system (ID) is immersed in a \SI{2}{T} axial magnetic field and provides charged particle tracking in the range $| \eta | < 2.5$. A high-granularity silicon pixel detector covers the vertex region and typically provides three measurements per track. It is followed by a silicon microstrip tracker, which usually provides four two-dimensional measurement points per track. These silicon detectors are complemented by a transition radiation tracker, which enables radially extended track reconstruction up to $| \eta | < 2.0$. The transition radiation tracker also provides electron identification information based on the fraction of hits above a higher energy-deposit threshold corresponding to transition radiation. Compared to Run-1, an Insertable B-Layer \cite{IBL} (IBL) is inserted as the innermost pixel layer during LS1 for Run-2, which significantly improves the tracking performance.

The calorimeter system covers the pseudorapidity range $| \eta | < 4.9$. Within the region $| \eta | < 3.2$, electromagnetic calorimetry is provided by barrel and endcap high-granularity liquid-argon (LAr) electromagnetic calorimeters, with an additional thin LAr presampler covering $| \eta | < 1.8$, to correct for energy loss in material upstream of the calorimeters. Hadronic calorimetry is provided by a scintillator-tile calorimeter, segmented into three barrel structures within $| \eta | < 1.7$, and two LAr hadronic endcap calorimeters.

A muon spectrometer (MS) comprises separate trigger and high-precision tracking chambers measuring the deflection of muons in a magnetic field generated by superconducting air-core toroids. The precision chamber system covers the region $| \eta |< 2.7$ with three layers of monitored drift tubes, complemented by cathode strip chambers in the forward region, where the background is highest. The muon trigger system covers the range $| \eta | < 2.4$ with resistive-plate chambers in the barrel, and thin-gap chambers in the endcap regions.

\subsection{Data set}
\label{sec:dataset}

This analysis is based on the full proton-proton data at a center-of-mass energy $\sqrt{s}=13$~TeV with a bunch spacing of 25~ns collected by ATLAS in Run-2. The following good run list (GRL) was used for the 2015 dataset:

\begin{centering}
{\texttt data15\_13TeV.periodAllYear\_DetStatus-v89-pro21-02}

{\texttt \_Unknown\_PHYS\_StandardGRL\_All\_Good\_25ns.xml}

\end{centering}
which corresponds to an integrated luminosity of 3.22 fb$^{-1}$.

The GRL used for the 2016 dataset:

\begin{centering}
{\texttt data16\_13TeV.periodAllYear\_DetStatus-v89-pro21-01\\\_DQDefects-00-02-04\_PHYS\_StandardGRL\_All\_Good\_25ns.xml}

\end{centering}
corresponds to an integrated luminosity of 32.9881 fb$^{-1}$.

These GRLs exclude data where the IBL was not fully operational. The uncertainty in the combined 2015+2016 integrated luminosity, 36.1~fb$^{-1}$, is $2.1\%$. It is derived, following a methodology similar to that detailed in Ref.~\cite{DAPR-2013-01}, from a calibration of the luminosity scale using x-y beam-separation scans performed in August 2015 and May 2016.

The GRL used for the 2017 dataset:

\begin{centering}
{\texttt data17\_13TeV.periodAllYear\_DetStatus-v99-pro22-01\\\_Unknown\_PHYS\_StandardGRL\_All\_Good\_25ns\_Triggerno17e33prim.xml}

\end{centering}
corresponds to an integrated luminosity of 44.307 fb$^{-1}$.

The GRL used for the 2018 dataset:

\begin{centering}
{\texttt  data18\_13TeV.periodAllYear\_DetStatus-v102-pro22-04\\\_Unknown\_PHYS\_StandardGRL\_All\_Good\_25ns\_Triggerno17e33prim.xml}

\end{centering}
corresponds to an integrated luminosity of 58.450 fb$^{-1}$. The final luminosity used for the analysis is 139.0 fb$^{-1}$.

\subsection{Signal and background simulation}
\label{sec:generator}

The overview of the major samples generated is summarized in Table \ref{mob}.

The TopFCNC UFO model \cite{FCNC_UFO1,FCNC_UFO2} with 5-flavour scheme is used for signal simulation.

The targeted signal in this analysis is $tt(qH)/tH$ with $\Htautau$ (samples 411170-411177 and 412098-412105) in App. \ref{sec:DSIDlist}.

The FCNC \textit{ST} signal is simulated using MadGraph5\_aMC@NLO v2.6.2 \cite{MG5} interfaced with Pythia 8 \cite{Pythia8} with the A14 tune \cite{A14} for the generation of parton showers, hadronisation and multiple interactions and the NNPDF30NLO \cite{NNPDF30NLO} parton distribution functions (PDF) is used to generate $qg$ events at next-to-leading order (NLO) in QCD. Depending on either up quark or charm quark involved in the FCNC decay and either the $W$ bosons decaying hadronically or leptonically, 4 samples are generated for each term of effective Lagrangian, so eight samples in total.

The FCNC \textit{TT} signal is simulated using Powheg-Box \cite{Powheg} V2 interfaced with Pythia8 \cite{Pythia8} with the A14 tune \cite{A14} for the generation of parton showers, hadronisation and multiple interactions and the NNPDF30NLO \cite{NNPDF30NLO} parton distribution functions (PDF) is used to generate $t\bar{t}$ events at next-to-leading order (NLO) in QCD. Depending on either the top or the anti-top quark decaying to $bW$, either up quark or charm quark involved in the FCNC decay and either the $W$ bosons decaying hadronically or leptonically, eight samples are produced with the Higgs decaying into a $\tau$-lepton pair.

Considering the other decays of the Higgs can be part of the signal, these samples are also included:

\begin{itemize}
	\item 411420-411427: production mode with $H\to ZZ$ and $H\to WW$.
	\item 411229-411232: $t\bar t$ with inclusive $W$ and Higgs decays. These sample have a one-lepton (electron or muon) filter at truth level (either coming from $W$ or Higgs decays).
\end{itemize}

The events in 411229-411232 with $\Htautau$ decay are removed based on truth information. The contributions from $H\rightarrow VV^*$ is small in the $t_l(t_h)+\thadhad$ channels.
Unfortunately, they are not negligible in the lepton + $\thad$ channels in the pre-selected signal regions as shown in App.~\ref{sec:HVVML}.
However, it is not easy to take them into account for signal as their current BDTs behave like the background and are shown in Figures~\ref{fig:BDT_tuH_HWW} - \ref{fig:BDT_tcH_HWW}. Since their systematics samples are still missing, we decide not to consider the HVV contribution
as part of signal for now and focus on the $H\rightarrow \tau\tau$ decay only. This has no significant impact on our limits as shown in
Table~\ref{tab:ml_limit}.

We also checked the overlap between two analysis frameworks used after the final selection,
there are 110 overlapped signal events caused by different overlap removal and object definition in xTauFramework and ttHMultiAna (27140 in total for hadhad channel and 95253 in total for lepton channels) but there is no overlap in the signal enriched region (BDT > 0.5).

The total FCNC signal with fake taus in this analysis is not used in the MVA training, but is regarded as part of the total signal in the fit. The normalization factor of the other components is common with the signal, so that their yields are fully correlated in the fit.

The dominant background is the $t\bar{t}$ production. The $t\bar{t}$ process and the single top process are generated with Powheg-Box \cite{Powheg} V2, and Pythia8 is used for the parton shower. NNPDF30NLO \cite{NNPDF30NLO} and A14 tune \cite{A14} are used for $t\bar{t}$(single top). The $t\bar{t}$ sample is also generated with different generators and parton showers models, as well as different amount of radiations, for systematics as detailed in Sec. \ref{sec:systematics}.

The $t\bar{t}X$, where X=$W$, $ee$, $\mu\mu$, $\tau\tau$ or $Z(qq,\nu\nu)$ are generated with MadGraph5\_aMC@NLO and inferfaced with Pythia8 for the parton shower. The NNPDF30NLO \cite{NNPDF30NLO} is used for the matrix element PDF. The $t\bar{t}$, single top and $t\bar{t}X$ are combined into a single process named top background in the analysis.

The $W$+jets, $Z$+jets and diboson backgrounds are simulated using Sherpa 2.2.1 \cite{Sherpa} with NNPDF30NNLO PDF \cite{NNPDF30NLO}.

%The $\tau$ decay in the single top samples is handled by Tauola \cite{Tauola}. All samples showered by Pythia8 (Sherpa) have the $\tau$ decays also handled by Pythia8 (Sherpa). All the decay modes of the $\tau$ lepton are allowed in the event generators (but may be subject to generator filters). The summary of used generators for matrix element and parton shower is given in Table \ref{mob}.
The decays and spin correlations for $\tau$-leptons are handled by Pythia8 for samples generated with Powheg while samples generated with Sherpa uses the implementation of the generator itself. The decays and spin correlations have been implemented in Pythia8 since 2014 and version 8.150~\cite{Pythia8TauDecay}. It has been thoroughly validated by comparing to other tools like Tauola~\cite{TauolaPhotosII}. The implementation in Sherpa has been validated in ATLAS by the Tau Working Group~\cite{ATLASTauGenValidation}.

The SM higgs background includes $ggH$, $VH$, $VBF$ and $t\bar{t}H$, generated from Powheg-Box \cite{Powheg} V2 interfaced with Pythia8. The overall contribution is pretty small. Various PDF and tune options are use for those samples depending on the decay modes.

The $tH$ associated production is negligible but we still considered it. The sample is generated using MadGraph5 and interfaced with pythia8 for parton shower. CT10 PDF and A14 tune are used. It is treated as part of SM higgs background explained in above.

Except the major background $V+$jets, $t\bar{t}$, SM higgs, Diboson, the other minor background are categorised into "Rare" processes in this analysis, which doesn't necessarily mean it's rare in the pp collision.

All Monte-Carlo (MC) samples were passed through the full GEANT4 \cite{GEANT4} simulation of the ATLAS detector, except for two extra \ttbar samples with Pythia8 and Herwig7 \cite{Herwig} parton showering which are simulated with ATLFAST-II \cite{AFII} for systematics (Sec. \ref{sec:systematics}). In the analysis, the simulated events were reweighted based on their pile-up to match the pile-up profile observed in data.

The full list of MC samples are given in App. \ref{sec:DSIDlist}. The single boson and diboson cross sections are calculated to NNLO \cite{bosonXsec}. The $t\bar{t}$ cross section is calculated at NNLO in QCD including resummation of NNLL soft gluon terms for a top-quark mass of 172.5 GeV \cite{ttXsec}. The $t\bar{t}H$ and $t\bar{t}V$ are normalized to NLO cross sections according to \cite{HiggsBR} and \cite{ttVXsec}. The $t$-channel and $s$-channel single top cross sections are calculated at NLO with Hathor v2.1 \cite{Hather1,Hather2}, while the $Wt$ channel is calculated at NLO+NNLL \cite{WtXsec}.

\begin{table}
\footnotesize
\centering
\caption{Overview of the MC generators used for the main signal and background samples}
\begin{tabular}[h]{l|c|c|c|c|c|c}
\hline \hline
\multirow{2}{*}{Process} & \multicolumn{2}{c|}{Generator} & \multicolumn{2}{c|}{PDF set} & \multirow{2}{*}{Tune} & \multirow{2}{*}{Order} \\ \cline{2-5}
        &  ME   &  PS    &  ME  & PS &   &  \\\hline
\textit{TT} Signal & Powheg & Pythia8 & NNPDF30NLO & NNPDF23LO & A14 & NLO \\ \hline
\textit{ST} Signal & MadGraph5\_aMC@NLO & Pythia8 & NNPDF30NLO & NNPDF23LO & A14 & NLO \\ \hline
$W/Z$+jets & \multicolumn{2}{c|}{Sherpa 2.2.1} & \multicolumn{2}{c|}{NNPDF30NNLO} & Sherpa & NLO/LO \\ \hline
\ttbar & Powheg & Pythia8 & NNPDF30NLO & NNPDF23LO & A14 & NLO \\ \hline
Single top & Powheg & Pythia8 & NNPDF30NLO & NNPDF23LO & A14 & NLO \\ \hline
$t\bar{t}X$ & MadGraph5\_aMC@NLO & Pythia8 & NNPDF30NLO & NNPDF23LO & A14 & NLO \\ \hline
Diboson & \multicolumn{2}{c|}{Sherpa 2.2.1} & \multicolumn{2}{c|}{NNPDF30NNLO} & Sherpa & NLO/LO \\ \hline\hline
\end{tabular}
\label{mob}
\end{table}


\section{Object reconstruction}
\label{sec:obj_reco}

In this section, various objects used in this analysis are defined, namely jets, electrons, muons, hadronically decaying taus and missing transverse energy. 

\subsection{Jets}
Jets are reconstructed using the anti-$k_t$ algorithm \cite{antikt} with a distance parameter $R=0.4$ applied to the particle flow candidates. Only jets with $\pt>25$~GeV and $|\eta|<4.5$ are considered by the $\met$ calculation and overlap removal procedure. To suppress jets produced in additional pile-up interactions, jets with $\pt<60$~GeV and $|\eta|<2.4$ are required to have a Jet Vertex Tagger (JVT \cite{JVT}) parameter larger than 0.2 (Medium working point). The JVT is the output of the jet vertex tagger algorithm used to identify and select jets originating from the hard-scatter interaction through the use of tracking and vertexing information. About $10\%$ of selected jets in the signal are in the forward detector region. After the above selection and overlap removal, a ``jet cleaning'' cut performed by JetCleaningTool with LooseBad working point is applied on all the jets, and the events with jets not passing this cut are discarded. Only the central jets with $|\eta|<2.4$ are considered in the analysis to reject pile-up contamination.

\subsection{b-tagging}
The {\texttt\scriptsize DL1r} \cite{btag1} algorithm is used to identify the jets initiated by $b$-quarks. A working point corresponding to an average efficiency of 70\% for jets containing $b$-quarks is chosen. We also checked the 77\% b-tag working point that gives the similar results.
This is true that the 77\% b-tag is more efficient to reject the ttbar background, but it also rejects more tau candidates that are btagged.

% wmyao merging ele and muon as light leptons: introducing tight isolation using PromptLeptonVeto: 
\subsection{Light leptons}
Electron candidates are identified by tracks reconstructed in the inner detector and the matched cluster of energy deposited in the electromagnetic calorimeter. Electrons candidates are required to have $E_{\text{T}} > 15$ GeV and $|\eta|<2.47$. The transition region, $1.37<|\eta|<1.52$, between the barrel and end-cap calorimeters is excluded. They are further required to pass a \texttt{loose + b-layer} likelihood-based identification point \cite{ElectronID} and a \texttt{FCLoose} isolation working point \cite{IsolationWP}. The electrons are further removed  if its cluster is affected by the presence of a dead frontend board in the first or second sampling or by the presence of a dead high voltage region affecting the three samplings or by the presence of a masked cell in the core. The electron is required to be consistent with the primary vertex by imposing on the trasverse impact parameter significance ($|d_0|/\sigma_{d0}<5$) and 
the longituinal impact parameter ($|\Delta z_0 sin\theta_l|<0.5$ mm) cuts. 

Muon reconstruction begins with tracks reconstructed in the MS and is matched to tracks reconstructed in the inner detector. Muon candidates are required to have $\pt>10$~GeV and $|\eta|<2.5$. A \texttt{Loose} identification selection \cite{MuonSelectionTool} based on the requirements on the number of hits in the ID and the MS is satisfied. A \texttt{FCLoose} isolation \cite{IsolationWP} criterion is also required. The transverse impact parameter requirement for muon is slightly tighter than for electron ($|d_0|/\sigma_{d0}<3$), while the longitudinal impact
parameter selection is the same. 

Tight isolation working points are also applied in some channels to reduce fake and non-prompt lepton contributions based a trained isolation boosted decision tree \texttt{PromptLeptonVeto} 
(PLIV), as described in Sec.~\ref{sec:Pliv}.

\subsection{Hadronic tau decays}
\label{sec:taurecon}
The hadronic tau candidates \cite{tau_sys1} are seeded by jets reconstructed by the anti-$k_t$ algorithm \cite{antikt}, which is applied on calibrated topo clusters \cite{topocluster} with a distance parameter of R=0.4. They are required to have $\pt > 20$~GeV and $|\eta|<2.5$. The transition region between the barrel and end-cap calorimeters ($1.37<|\eta|<1.52$) is excluded.

In the hadronic channels, these tau candidates are considered in the overlap removal procedure and missing transverse energy calculation, following the Htautau group \cite{Htautau-note}. In the analysis event selection, the hadronic tau candidates are required to have one or three charged tracks and an absolute charge of one. An identification algorithm based on Recursive Neural Network (RNN) \cite{tau_sys2} is applied to discriminate the visible decay products of hadronically decaying tau lepton $\tauhad$ from jets initiated by quarks or gluons. Different RNN working points are used at different levels depending on the analysis channel. Only events with RNN Medium taus are considered to be signal in the hadronic channels while taus not passing the RNN Medium are only used in the control regions for fake tau estimation.

In the leptonic channels, the taus passing the RNN Loose working point are considered in the overlap removal procedure and missing transverse energy calculation, following the ttW multi-lepton analysis \cite{ttHMLgroup}, which is more focused on leptons.

The OLR and MET calculation procedures in hadronic channels are more forgiving in terms of taus since there are constantly two hadronic taus, and in the fake estimation, the taus not passing the RNN Medium are also used. This way we can benefit from better statistics and also be consistent with the W+jet regions used in the SM $\Htautau$ group where the Fake Factors are derived.

For the \texttt{Medium} ID, the tau efficiency is about 75\% (60\%) for 1-prong (3-prong) candidates. The ID efficiencies are optimized to be flat versus the tau $\pt$ and pileup.

The tau candidates are required to not overlap with a very loose electron candidate, and a dedicated BDT variable is also used to veto the taus which are actually electrons. The muon veto and the btag veto with 70\% are also applied. 

Efficiency scale factors for tau reconstruction, ID and electron BDT rejection \cite{TauCP} are applied on tau candidates in MC.

\subsection{Missing transverse energy}
The missing transverse energy $\met$ is computed using the fully calibrated and reconstructed physics objects as described above. The TrackSoftTerm (TST) algorithm is used to compute the SoftTerm of the $\met$ \cite{MET}. 

%wmyao add Improved PromptLeptonVeto 
\subsection{Tight lepton isolation: \texttt{PromptLeptonImprovedVeto}(PLIV)}
\label{sec:Pliv}
A dedicated isolation boosted decision tree has been trained to better reject non-prompt leptons and fakes produced in hadron decays~\cite{ATL-COM-PHYS-2018-410}. The main idea is to identify non-prompt light leptons using lifetime information associated with a track jet that matches the selected light lepton. These additional reconstructed charged particle tracks inside the jet can be used to increase the precision of identifying the displaced decay vertex of heavy flavor (b, c) hadrons that produced non-prompt leptons.

The \texttt{PLIV} is trained on leptons selected from the Powheg+Pythia8 non-allhad $t\bar t$ sample using eight input variables:
\begin{itemize}
\item Three of them are used to identify b-tagged jets by ATLAS flavor tagging algorithms;
\item Two of them are the ratio of the track lepton $\pt$ with respect to the track jet $\pt$ and $\Delta R$ between the lepton and the track jet axis;
\item Three of them are the number of tracks collected by the track jet and the lepton track and calorimeter isolation variables. 
\end{itemize}

The \texttt{PLIV} shows a significant improvement for non-prompt-lepton rejection compared to the cut-based isolation variables.

The tight working points are: \texttt{PLIV}$<-0.6734$ for high $\pt$ muons and \texttt{PLIV}$<-0.704$ for hight $\pt$ barrel electrons. The scale factors for the efficiencies of the tight \texttt{PLIV} working points are measured using the tag and probe method with $Z\rightarrow l^+l^-$ events. These scale
factors are also checked applicable to the electron or muon from the tau decay using $Z\rightarrow\tau\tau\rightarrow e\mu$ samples in App.~\ref{sec:CheckPLIV}.
The efficiencies of the PLIV tight cut in data(MC) are $0.741\pm 0.0074$ ($0.757\pm 0.011$) for tau-electron and $0.785\pm 0.010$($0.803\pm 0.011$) for tau-muon, where the uncertainties are dominated by the fake subtraction in the data using the excess of same-sign events and the MC statistics.
The ratio of the efficiencies for tau-lepton between data and MC (scale factor) is 0.98+-0.02(total), which is consistent with 1 at a sigma level for
both electron and muon. To be conservative, we assign additional $\pm 2\%$ systematic uncertainty for the PLIV efficiency for the tau-lepton in
the lepton+$\thad$ channels.
%The scale factors are approximately 0.92 for $10<\pt<15$ GeV muons and 0.97 for electrons, and averaging at 0.98 to 0.99 for higher $\pt$ leptons.

\subsection{Overlap removal}
For the objects passing the selection above, a geometric overlap removal is applied to eliminate the ambiguity in the object identification.  When two objects are close geometrically with $\Delta R$ less than a certain threshold, or satisfy some certain requirements, one of them will be removed. 

In the hadronic channels, the overlap removal is done by the official overlap removal tool provided by ASG group. The "Standard" working point is used. The rules are described as follows in sequence:

\begin{itemize}
\item If two electrons have a overlapped second-layer cluster, or shared tracks, the electron with lower $\pt$ is removed.
\item $\tauhad$ within a $\Delta R=0.2$ cone of an electron or muon are removed.
\item If a muon sharing an ID track with an electron and the muon is calo-tagged, the muon is removed. Otherwise the electron is removed.
\item Jets within a $\Delta R=0.2$ cone of an electron are removed.
\item Electrons within a $\Delta R=0.4$ cone of a jet are removed.
\item When a muon ID track is ghost associated to a jet or within a $\Delta R=0.2$ cone of a jet, the jet is removed if it has less than 3 tracks with $\pt>500$ MeV or has a relative small $\pt$ ($\pt^{\mu}>0.5\pt^{\text{jet}} \text{ and } \pt^{\mu}>0.7[\text{the scalar sum of the } \pt \text{'s of the jet tracks with } \pt>500$ MeV]).
\item Muons within a $\Delta R=0.4$ cone of a jet are removed.
\item Jets within a $\Delta R=0.2$ cone of the leading $\tauhad$ ($\tlhad$), or with the two leading $\tauhad$'s ($\thadhad$), are excluded. The overlap also works for the reverted tau ID regions used in the analysis, since the tau ID information is not used.
\item If a tau candidate is tagged as b-jet with 70\% working point, the tau is removed.
\end{itemize}

In the leptonic channels, the overlap removal is done using the heavy flavor overlap removal working point, which gives precedence to the b-tagged jet as follows:
\begin{itemize}
\item If two electrons have overlapped second-layer cluser, or shared tracks, the electron with lower $\pt$ is removed.
\item $\tauhad$ within a $\Delta R=0.2$ cone of an electron or muon are removed.
\item If a muon sharing an ID track with an electron and the muon is calo-tagged, the muon is removed. Otherwise the electron is removed.
\item Jet is not tagged as b-jet and within a $\Delta R=0.2$ cone of an electron is removed.
\item When a muon ID track is ghost associated to a jet or within a $\Delta R=0.2$ cone of a jet, the jet is removed if it is not tagged as b-jet and has either less than 3 tracks with $\pt>500$ MeV or
  has a relative small $\pt$ ($\pt^{\mu}>0.5\pt^{\text{jet}} \text{ and } \pt^{\mu}>0.7[\text{the scalar sum of the } \pt \text{'s of the jet tracks with } \pt>500$ MeV]).
\item Muons within a $\Delta R=0.4$ cone of a jet are removed.
\item Jet is not tagged as b-jet and within a $\Delta R=0.2$ cone of the $\thad$ is removed. The overlap also works for the reverted tau ID regions used in the analysis.
\item The event is removed if a tau candidate is tagged as b-jet with 70\% working point.
\end{itemize}

Note that the $\met$ calculation package has its own overlap removal procedure. Only two leading taus are considered in the calculation.
